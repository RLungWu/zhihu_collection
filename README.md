# zhihu_collection

| No.| Title | Summary | Feedback |
| :--: | :--: | :--: |:--:| 
|1| [LLM 推理加速](https://zhuanlan.zhihu.com/p/17811924624?utm_psn=1861592084353540096)  |  |  |
|2|[大模型的基本功](https://zhuanlan.zhihu.com/p/716344766?utm_psn=1857956031679840257)|
|3|[DPO对齐，用脏话数据教AI说真话](https://zhuanlan.zhihu.com/p/18945731214)|
|4|[手搓一个最小的 Agent 系统 — Tiny Agent](https://zhuanlan.zhihu.com/p/699732624)|
|5|[一文讲明白大模型显存占用（只考虑单卡）](https://zhuanlan.zhihu.com/p/713256008?utm_psn=1850877468791164928)|
|6|[Nips2024-Agent方向论文（上）](https://zhuanlan.zhihu.com/p/12317898153?utm_psn=1851404730472992768)|
|7|[基于LLM+向量库的文档对话痛点及解决方案](https://zhuanlan.zhihu.com/p/651179780?utm_psn=1851983465051975682)|
|8|[RAG（检索增强生成）会不会消亡呢？](https://www.zhihu.com/question/637421964/answer/33309712475?utm_psn=1852132878818869248)|
|9|[LightRAG技术框架解读](https://zhuanlan.zhihu.com/p/13261291813?utm_psn=1853075329633091584)|
|10|[大家觉得做一个大模型检索增强生成（RAG）系统，最难搞定的是那部分工作？](https://www.zhihu.com/question/642650878/answer/57968449225?utm_psn=1853197485889163265)|
|11|[万字长文梳理2024年的RAG](https://zhuanlan.zhihu.com/p/14116449727?utm_psn=1854663568068308992)|
|12|[我没有大模型经验，可以给个机会吗？](https://zhuanlan.zhihu.com/p/715031517?utm_psn=1857139809681805312)|
|13|[大模型如何高效部署？CMU最新万字综述纵览LLM推理MLSys优化技术](https://zhuanlan.zhihu.com/p/677635306?utm_psn=1857485262482989056)|
|14|[大模型的基本功](https://zhuanlan.zhihu.com/p/716344766?utm_psn=1857956031679840257)|
|15|[2024年大模型基础设施领域（训练、推理、硬件）有什么值得关注研究方向？](https://www.zhihu.com/question/637480772/answer/3474883101?utm_psn=1857961419003269120)|
|16|[LLM 推理加速](https://zhuanlan.zhihu.com/p/17811924624?utm_psn=1861592084353540096)|
|17|[为什么4090速度比A100快很多呢？](https://www.zhihu.com/question/615946801/answer/3205148871?utm_psn=1862858783665049600)|
|18|[LLM 推理加速方式汇总](https://zhuanlan.zhihu.com/p/688736901?utm_psn=1863541831435968512)|
|19|[mini_qwen：从0开始训练1B参数的大模型](https://zhuanlan.zhihu.com/p/19353252686?utm_psn=1864662479939985408)|
|20|[【代码+数据集】DPO对齐，用脏话数据教AI说真话](https://zhuanlan.zhihu.com/p/18945731214?utm_psn=1865208193703079937)|
|21|[SFT、RLHF、DPO、IFT —— LLM 微调的进化之路](https://zhuanlan.zhihu.com/p/710652762?utm_psn=1865532802738552833)|
|22|[如何评价 DeepSeek 的 DeepSeek-V3 模型？](https://www.zhihu.com/question/7837132971/answer/72079893262?utm_psn=1866102231436230656)|
|23|[给AI喂了4000句脏话，它竟然开始觉醒说真话了！(附代码)](https://zhuanlan.zhihu.com/p/18745659547?utm_psn=1868373722618028032)|
|24|[手搓一个最小的 Agent 系统 — Tiny Agent](https://zhuanlan.zhihu.com/p/699732624?utm_psn=1869109101595873280)|
|25|[大模型炼丹术：大模型微调总结及实现](https://zhuanlan.zhihu.com/p/673789772?utm_psn=1869111520702648321)|
|26|[Deepseek V3 预训练解读](https://zhuanlan.zhihu.com/p/15073492309?utm_psn=1869173633865375746)|
|27|[深入理解 Megatron-LM（1）基础知识](https://zhuanlan.zhihu.com/p/650234985?utm_psn=1869377491669479425)|
|28|[大家觉得做一个大模型检索增强生成（RAG）系统，最难搞定的是那部分工作？](https://www.zhihu.com/question/642650878/answer/86323321960?utm_psn=1871330803125997569)|
|29|[LLM的MoE架构的“动态路由”为什么能训练出来？](https://www.zhihu.com/question/11450572647/answer/95847905917?utm_psn=1871984789910872064)|
|30|[再读MLA，还有多少细节是你不知道的](https://zhuanlan.zhihu.com/p/19585986234?utm_psn=1871987158165897216)|
|31|[【必看】LLM历史技术文章导航](https://zhuanlan.zhihu.com/p/654910335?utm_psn=1871995513445957632)|
|32|[大模型推理加速技术的学习路线是什么?](https://www.zhihu.com/question/591646269/answer/3333654552?utm_psn=1872750354279559168)|
|33|[deepseek技术解读(1)-彻底理解MLA（Multi-Head Latent Attention）](https://zhuanlan.zhihu.com/p/16730036197?utm_psn=1872639045261217792)|
|34|[拆解大语言模型RLHF中的PPO](https://zhuanlan.zhihu.com/p/645225982?utm_psn=1872250276049715201)|
|35|[开源DeepResearch：24小时挑战，重现OpenAI的AI Agent奇迹](https://zhuanlan.zhihu.com/p/22559225933?utm_psn=1872248791379357697)|Duplicate||
|36|[一个博士生接受怎样的训练是完整、全面的科研训练？](https://www.zhihu.com/question/384512106/answer/3556664044)|[Summary](./zhihu/36/No36.md)||
|37|[RAG（检索增强生成）会不会消亡呢？](https://www.zhihu.com/question/637421964/answer/99446183305?utm_psn=1873430932557537280)|
|38|[从零到一打造商用 AI Agent（智能体)](https://zhuanlan.zhihu.com/p/23285829505?utm_psn=1873432769390051328)|
|39|[大模型推理加速技术的学习路线是什么?](https://www.zhihu.com/question/591646269/answer/102260978569?utm_psn=1874459723065081858)|
|40|[2025年大模型LLM还有哪些可研究的方向？](https://www.zhihu.com/question/11285951981)|[Summary](./zhihu/41/)|
|41|[解读Open-source DeepResearch](https://zhuanlan.zhihu.com/p/22733177444)|
|42|[从零实现一个MOE（专家混合模型）](https://zhuanlan.zhihu.com/p/701777558?utm_psn=1875507800106467329)|
|43|[RAG、LangChain、Agent 到底有啥关系？](https://www.zhihu.com/question/2495164206/answer/86964072894?utm_psn=1875623080514158592)|
|44|[7 MLOPs Projects for Begineers](https://www.kdnuggets.com/7-mlops-projects-beginners)|
|45|[如何把deepseek-R1微调/蒸馏为某领域的一个专家？](https://www.zhihu.com/question/10555876430/answer/104851046659)|
|46|[Llama模仿Diffusion多模态涨分30%！只需共享注意力分布](https://zhuanlan.zhihu.com/p/24207646579)|
|47|[从零搭建自己的 Multi-Agent](https://zhuanlan.zhihu.com/p/23104679193?utm_psn=1875954926837964800)|
|48|[llm reasoning/ theory of llm 从入门到入土](https://zhuanlan.zhihu.com/p/24665806059?utm_psn=1875959409554903040)|
|49|[笔记：MoBA 与 Native Sparse Attention](https://zhuanlan.zhihu.com/p/24774848974?utm_psn=1875959707941867520)|
|50|[目前大模型量化方案有很多，有哪些比较SOTA的量化方案？](https://www.zhihu.com/question/10439431486/answer/86095724572?utm_psn=1875983114599268352)|
|51|[笔记：关于 LLM MLSys 研究的一些思考](https://zhuanlan.zhihu.com/p/720634180?utm_psn=1877109033598582784)|
|52|[AI Agent目前应用落地有哪些局限性？](https://www.zhihu.com/question/624354739/answer/95596641305?utm_psn=1876811850999533568)|
|53|[笔记：关于 LLM MLSys 研究的一些思考](https://zhuanlan.zhihu.com/p/720634180?utm_psn=1877109033598582784)|
|54|[大模型面试：RAG项目的拷问（文字版）](https://zhuanlan.zhihu.com/p/3448487946?utm_psn=1880380835355669111)|
|55|[以RLer视角看大模型训练中的强化学习](https://zhuanlan.zhihu.com/p/23290969372?utm_psn=1880357438890415094)|
|56|[深入理解构建和优化大语言推理模型的方法和策略](https://zhuanlan.zhihu.com/p/28530752474?utm_psn=1881823435275080134)|
|57|[大模型Post-training的范式可能已经发生变化了](https://zhuanlan.zhihu.com/p/28584030587?utm_psn=1881768454979297519)|
|58|[学习检索增强生成 RAG时，多数人是不是从Llamaindex学起，首先研究和改写哪个RAG开源代码？](https://www.zhihu.com/question/659305847/answer/119512863129?utm_psn=1881759616964203347)|
|59|[从啥也不会到CUDA GEMM优化](https://zhuanlan.zhihu.com/p/703256080?utm_psn=1881410562489034686)|